
\section{Admin/DevOps' Requirements}
\label{sec:requirements}

% \begin{figure}[t]
%   \centering
%   \def\svgwidth{\columnwidth}
%   \input{figures/sites.pdf_tex}
%   \caption{Partial representation of the targeted Edge infrastructure, composed
%     of multiple sites. Each site is composed of many servers (represented by
%     black bullets) and have a set of users (depicted by black squares). The red
%     dashed line depicts a split-brain situation that separates the
%     infrastructure into $2$ partitions, isolating \emph{Site 1} from \emph{Site
%     2} and \emph{3}.}
%   \label{fig:fogedge-archi}
% \end{figure}

\begin{table*}
    \centering
        \input{tab_req.tex}
    \caption{Classification of the requirements to administrate and use Edge
    Computing infrastructures in $5$ levels.}
    \label{tab:requirements}
\end{table*}

In this section, we classify features administrators and DevOps expect
to find in the context of Edge Computing infrastructures.
Our classification is based on $5$ \emph{levels}, starting from the easiest
aspects, \ie interacting with a single site (considered in level 1 or L1), to
more complex aspects like managing multiple sites (L2), up to considering that
sites can be owned by different operators (L5).
\Cref{tab:requirements} summarizes the classification we detail in the following.

As previously mentioned, a large part of these features are common to
the ones offered by current IaaS resource management systems. They are
implemented by various services, each of which is in charge of the
management of a particular aspect of the infrastructure
%.In this paper, we consider the Compute, Storage and
%Network managers as well as the monitoring and administrative
%tools
~\cite{moreno2012csp}.
\ALm{Not sure whether we should introduce
  service here. Maybe this is something we should only put at the end
  of this section to make a transition with the other ones. The issue
  is that we need it for the moment in L2.}

\paragraph{L1. Operate/use any site}
As depicted in the second row of \cref{tab:requirements}, this level
considers actions both administrators and users expect to perform
when considering a single site, supposing the site is reachable.
%
Most operations are elementary from the Edge viewpoint because they correspond
to the ones already provided by OpenStack for both administrators and DevOps.
In other words, each Edge site can be considered as an independent Cloud at
this level. The unmanned aspect only impacts this level by requiring to perform
all operations remotely if needed.
%security
Furthermore, the resource management system should provide means to
ensure the integrity of the hardware resources taking part to the Edge
infrastructure. Strategies such as enabling/disabling physical
interactions with the equipment should be considered.

% %
% Regarding administrators,  Administrators should be able to
% install and upgrade the aforementioned resource management
% services. After what, they can use those services to manage
% users, accesses, flavors (\ie available capacities of compute
% resources) and quotas.

% Regarding DevOps, they should be able to provision compute, network or
% storage resources like any traditional Cloud platform, supposing they
% are authorized to.

% In addition, admins and users share common expectations.
% % collect metrics
% First they want to monitor various metrics related to resources,
% users, and projects . This is used for instance for
% respectively managing quotas and listing existing resources.

\paragraph{L2. Operate/use several sites}

%% TODO
% For instance, a user of \emph{Site 1}
In L2, L1 features are considered but over multiple sites (at least two). This
includes operations such as provisioning a resource on a site using resources
from another one, managing several resources or gathering information from
various sites simultaneously.
%(interconnecting two VMs with a dedicated network).
Operations can be either intra-services (same service from different sites) or
inter-services (different services from different sites).

Concrete operations consist for instance in configuring users'
access on a per-site basis, listing available VM images or pushing new
ones on multiple sites (intra-service operations). From the
DevOps viewpoint, a user should be able to boot a VM on \emph{Site 1} (depicted
on \cref{fig:fogedge-archi}) using an image defined in \emph{Site 2}
(inter-service operation). Similarly to L1, they both expect metrics collected
from several sites and collaborated mechanisms regarding the security (\eg
secret key sharing, network encryption).

Because collaboration between sites can be either explicit (\ie the
targeted sites are explicitly specified in the operation), or implicit
(\ie the resource management system is in charge of selecting
resources), we have defined two sub-levels as depicted in
\cref{tab:requirements}, respectively called L2.1 and L2.2. The implicit
manner suggests that policies (\eg performance objectives, energy
consumption) and constraints (\eg affinity rules, underlying hardware
requirements) are provided by admins and DevOps so that the resource management
system takes the right decisions regarding the defined desiderata and the state
of the infrastructure (\eg auto-scaling, relocating workloads between sites,
re-scheduling faulty resources across sites).
% should be elaborated and/or refs should be given here

\paragraph{L3. Robustness \wrt network split brains}
The next level we define is related to the limited or intermittent
network connections between sites. Similarly to the previous level,
L3 includes all L2 operations but with the possibility to face
\emph{network split brains} (\ie, situations where the infrastructure is
partitioned due to communication failures).
%
\Cref{fig:fogedge-archi} depicts such a case where \emph{Site 1} is isolated
from the other sites. In this scenario, administrators/DevOps that can reach
the site (\ie located in the same geographical area) should be able to perform
L1 operations regarding \emph{Site 1}, even if it is isolated from other sites.
Such a requirement make sense as L1 operations are only related to one site and
thus do not impact the other ones.
%
Regarding the second partition which contains the other sites, L1 and L2
operations must be guaranteed for any subset of sites inside the partition.

Split brains have a distinct impact on already-provisioned resources and on the
management services that enable to provision new resources or change existing
ones. As a consequence, we decided to refine L3 into two sub-classes. L3.1 is
related to the features that allow already-deployed applications to continue to
serve local requests without being impacted. For instance, an \emph{apache}
server or a storage backend should be able to satisfy requests coming from the
same geographical area, even if management services cannot be reached. L3.2
features are related to the provisioning of new resources and other management
operations as described in the previous paragraph.
%
Note that guaranteeing L2 features will not be always possible at the L3.2
level because information cannot be gathered in case of a disconnection. For
instance, guaranteeing quotas across the infrastructure overall is impossible
without relaxing the consistency of the information. New approaches will have
to be proposed for such operations.

Finally, the possibly intermittent network connectivity between Edge resources
requires to have operations that enable sites to join and leave the
infrastructure.

% what about quotas? how to manage them in case of split-brain?
% suppose a user has a global quotas on several sites, it is impossible to
% determine its global consumption in case of split-brains?

\paragraph{L4. Multiple Cloud environments}
Delivering a resource management system at large scale in a unified manner is
not conceivable from the software viewpoint. Different versions of each
service, and potentially different infrastructure managers in charge of
different sites, will co-exist at the same time across the whole
infrastructure. It is thus important to consider specific requirements to deal
with such a constraint, which we gather in L4.
%
More precisely, L4.1 considers L3 features when Edge sites can be
operated by different versions of the same software stack.
%
L4.2 increases the complexity by adding into the big picture the
possibility to deal with different resource management systems,
including possibly different concepts (\eg OpenStack for VMs and
Kubernetes for Containers).

As a consequence, it is necessary to discover sites' capabilities to
determine their relationship in order to only allow possible operations.

\paragraph{L5. Multiple operators}
L5 corresponds to the holy grail in terms of expected features. In
addition to L4 features, it includes the possibility to use sites
owned by different operators. As depicted in \cref{tab:requirements},
we do not specify any requirement for administrators because an
operator would not share administrative rights to their sites with
other operators at the first sight. However, operators should be able
to collaborate to offer their sites' resources to any DevOps like it has
been done for a while for cellular networks. The requirements here are more
related to the collect and share of relevant metrics enabling each operator to
correctly establish bills.

%footer
\paragraph{Summary}
As noticed in the beginning of this section, we choose to classify the
requirements through 5 levels, each one increasing the complexity in
terms of design and development constraints. We underline that since
L4 and L5 both extend L3 respectively with multiple manager
environments, and multiple operators, they can be considered at the
same level in our classification and can be swapped as a consequence.

Although we tried to be exhaustive, this list of features could
probably be extended, in particular, by considering different Edge
infrastructure scenarios including for instance smaller and limited devices.
However, we believe it is already valuable to deliver significant
insights on the design and implementation of a resource management
system for the Edge Computing. In the next section, we study whether a
system such as OpenStack can fulfill the L1, L2, and L3 levels.
The discussion of L4 and L5 is let as future work.

%Considering now that the challenges are already numerous with L1, L2 and L3, we
%propose to drive the system design regarding these levels in the rest of the
%paper (leaving L4 and L5 for future works).
