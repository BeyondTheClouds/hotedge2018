
\section{Administrators and Developers/End-users' Requirements}
\label{sec:requirements}

% \begin{figure}[t]
%   \centering
%   \def\svgwidth{\columnwidth}
%   \input{figures/sites.pdf_tex}
%   \caption{Partial representation of the targeted edge infrastructure, composed
%     of multiple sites. Each site is composed of many servers (represented by
%     black bullets) and have a set of users (depicted by black squares). The red
%     dashed line depicts a split-brain situation that separates the
%     infrastructure into $2$ partitions, isolating \emph{Site 1} from \emph{Site
%     2} and \emph{3}.}
%   \label{fig:fogedge-archi}
% \end{figure}

\begin{table*}
    \centering
        \input{tab_req.tex}
    \caption{Classification of the requirements to administrate and use edge
    computing infrastructures in $5$ levels.}
    \label{tab:requirements}
\end{table*}

As previously mentioned, administrators and users of edge infrastructures
expect to get a set of high level mechanisms whose assembly results in a system
capable of operating and using a geo-distributed IaaS infrastructure.
Such mechanisms are provided various management services, each of which is in
charge of an aspect of the infrastructure management. In this paper, we
only consider a minimal set of a such services required to operate
infrastructure resources: Compute, Storage and Network managers, monitoring and
administrative tools~\cite{moreno2012csp}.
%However, considering each of these services independently is not
%sufficient enough to identify the challenges our community should deal with.
In this section, we classify the features administrators and
developers/end-users expect from those services, in the context of edge
computing, highlighting the differences with federated Cloud infrastructures.
\AL{Polish (in particular by adding a transition)}
Our classification is based on $5$ \emph{levels}, starting from the easiest
aspects, \ie interacting with a single site (considered in level 1 or L1), to
more complex aspects like managing multiple sites (L2), up to considering that
sites can be owned by different operators (L5).
\Cref{tab:requirements} summarizes the classification we detail in the following. 

\paragraph{L1: Operate/use any site}
As depicted in the second row of \cref{tab:requirements}, this level considers
the actions both administrators and users expect to perform on a single site.
Regarding the administration side, operating a single site like \emph{Site 1},
illustrated in \cref{fig:fogedge-archi}, requires that admins are able to
install and upgrade the resource management services presented previously.
After what, admins expect to use those services to manage users, accesses,
flavors (\ie available capacities of compute resources) or quotas, regarding
\emph{Site 1}.

Regarding end-users, they expect to be able to provision compute, network or
storage resources on any single site, supposing they are authorized to. For
instance, a user of \emph{Site 1} should be able to boot a VM in \emph{Site 2},
using images, flavors or networks defined in \emph{Site 2} -- as long as the
site is reachable.

In addition, admins and users share a set of expectations.
% collect metrics
First they expect metrics to be monitored (\eg metrics related to resources,
users, and projects) from any single site. This is used for instance for
respectively managing quotas and listing existing resources.
% security
Regarding the security aspects, communications are expected to be secured (\eg
isolated, encrypted) and actions must be logged for auditing. Compared to
federated Clouds, Edge sites are potentially unmanned. As a consequence,
physical and application integrity must be monitored at each site, autonomous
corrective actions should be triggered when required.
% resiliency
Furthermore, compared to federated infrastructures, Edge infrastructures are
dynamic, \ie sites can join and leave the infrastructure, on purpose or due to
intermittent network access. As a consequence, tools need to resilient to this
churn effect.

\paragraph{L2: Operate/use several sites:}
We now consider in this level that the operations previously defined in L1
cover at least two sites. For instance, an administrator might desire to
configure users access on a per-site basis. Regarding users, they also expect
a collaboration between sites to boot, for instance, a VM on \emph{Site 1},
using an image defined in \emph{Site 2}. To that end both administrators and
users require to collect data that belong to several sites. We define here two
sub-levels as depicted in \cref{tab:requirements}. Such collaboration between
sites can be either explicit (\ie the targeted sites are explicitly specified),
referenced as the sub-level L2.1, or implicit (L2.2). The implicit manner
suggests that policies (\eg performance objectives, energy consumption) and
constraints (\eg affinity, underlying hardware) are provided by admins and users so
that an edge-aware orchestrator takes the right decisions regarding the users'
desiderata and the state of the infrastructure (\eg auto-scaling, relocating
workloads between sites, re-scheduling faulty resources across sites).
% should be elaborated and/or refs should be given here

\paragraph{L3: Robustness wrt split brains:}
In this level, we now consider split brains which correspond to the situation
where the infrastructure is partitioned due to communication failures.
\Cref{fig:fogedge-archi} depicts such situation where \emph{Site 1} is isolated from
\emph{Site 2} and \emph{3}. In such case, all operations defined in L1 must be
guaranteed for a partition composed of a single site like \emph{Site 1}
(supposing it is reachable). For instance, a user in \emph{Site 1} should be
able to use \emph{Site 1}'s resources despite the split brain. Regarding
partitions containing several sites, L1 and L2 operations must be guaranteed
for any set of sites inside the partition.
% what about quotas? how to manage them in case of split-brain?
% suppose a user has a global quotas on several sites, it is impossible to
% determine its global consumption in case of split-brains?
Two sub-levels are proposed here: L3.1 considers the robustness of already
deployed resources (\eg a user should be able to access a deployed application
despite the split brain, if he can reach the related site), while the
robustness of management services, treated in L3.2, is required for both admins
and users.
% tricky issue: management of split brain between collaborative services in
% different sites

\paragraph{L4: Multiple Cloud environments:}
Since edge infrastructures are dynamic infrastructures where sites can join and
leave, different versions of an IaaS manager can exist on different sites. One
requirement here is to consider L3 requirements between sites operated by
different manager versions (L4.1). Another requirement is to prevent vendor
lock-in between multiple generic IaaS manager technologies (\eg OpenStack,
CloudStack), and container orchestrators like Kubernetes (L4.2).
As a consequence, it is necessary to discover site's capabilities to determine
their compatibilities. For instance, it is not possible to migrate a VM from
\emph{Site 1} to \emph{Site 2} if the latter is managed by a container
orchestrator.

\paragraph{L5: Multiple operators:}
We now consider that sites can be owned by different operators. As depicted in
\cref{tab:requirements}, no requirements is expected by administrators since an
operator should not be able to administrate another operator's sites. However,
operators should be able to collaborate to offer their resources to users.
Specific metrics should be collected at the scope of operators to manage for
instance billing between them.

