
\section{Admin/Devops' Requirements}
\label{sec:requirements}

% \begin{figure}[t]
%   \centering
%   \def\svgwidth{\columnwidth}
%   \input{figures/sites.pdf_tex}
%   \caption{Partial representation of the targeted edge infrastructure, composed
%     of multiple sites. Each site is composed of many servers (represented by
%     black bullets) and have a set of users (depicted by black squares). The red
%     dashed line depicts a split-brain situation that separates the
%     infrastructure into $2$ partitions, isolating \emph{Site 1} from \emph{Site
%     2} and \emph{3}.}
%   \label{fig:fogedge-archi}
% \end{figure}

\begin{table*}
    \centering
        \input{tab_req.tex}
    \caption{Classification of the requirements to administrate and use edge
    computing infrastructures in $5$ levels.}
    \label{tab:requirements}
\end{table*}

In this section, we classify features administrators and devops expect
to find in the context of Edge Computing infrastructures.
Our classification is based on $5$ \emph{levels}, starting from the easiest
aspects, \ie interacting with a single site (considered in level 1 or L1), to
more complex aspects like managing multiple sites (L2), up to considering that
sites can be owned by different operators (L5).
\Cref{tab:requirements} summarizes the classification we detail in the following. 

As previously mentioned, the assembly of these features results in a
system capable of operating and using a geo-distributed IaaS
infrastructure.  Such mechanisms are provided by various services,
each of which is in charge of the management of a particular aspect of
the infrastructure. In this paper, we consider the Compute, Storage
and Network managers as well as the monitoring and administrative
tools~\cite{moreno2012csp}.
\RACm{Maybe this paragraph can be removed}

\paragraph{L1: Operate/use any site}
As depicted in the second row of \cref{tab:requirements}, this level
considers actions both administrators and users expect to perform
when considering a single site, supposing the site is reachable.
%
Most operations are elementary from the Edge viewpoint because they
correspond to the ones already provided by OpenStack for both administrators and devops.  In other words,
each Edge site can be considered as an independent Cloud at this
level. The unmanned aspect only impacts this level by requiring to perform all operations
remotely if needed.
%security
Furthermore, the resource management system should provide means to
ensure the integrity of the hardware resources taking part to the edge
infrastructure. Strategies such as enabling/disabling physical
interactions with the equipment should be considered.

% %
% Regarding administrators,  Administrators should be able to
% install and upgrade the aforementioned resource management
% services. After what, they can use those services to manage
% users, accesses, flavors (\ie available capacities of compute
% resources) and quotas.

% Regarding devops, they should be able to provision compute, network or
% storage resources like any traditional Cloud platform, supposing they
% are authorized to.

% In addition, admins and users share common expectations.
% % collect metrics
% First they want to monitor various metrics related to resources,
% users, and projects . This is used for instance for
% respectively managing quotas and listing existing resources.

\paragraph{L2: Operate/use several sites:}

%% TODO
% For instance, a user of \emph{Site 1} 
In L2, L1 operations are considered but over multiple sites (at least
two).  This includes operations such as gathering information of
several sites, creating a new resource one a particular site using
resources from another one~\ldots.
%
Concrete operations might consist for administrators in configuring users' access on a per-site basis.


Regarding users, they expect
services from different sites to collaborate.
% is the following interesting regarding the scope of this paper?
% a reflection would need deeper analysis/explanations
Operations can be either intra-services (same service from different sites) or
inter-services (different services from different sites).
%
For instance, users might desire to boot a VM on \emph{Site 1}, using an image
defined in \emph{Site 2} (inter-service operation) or list VMs from multi-sites
(intra-service operation). Similarly to L1, they both expect metrics collected
from several sites and collaborated mechanisms regarding the security (\eg
secret key sharing).

We define here two sub-levels as depicted in \cref{tab:requirements}. Such
collaboration between sites can be either explicit (\ie the targeted sites are
explicitly specified), referenced as the sub-level L2.1, or implicit (L2.2).
The implicit manner suggests that policies (\eg performance objectives, energy
consumption) and constraints (\eg affinity, underlying hardware) are provided
by admins and users so that an edge-aware orchestrator takes the right
decisions regarding the users' desiderata and the state of the infrastructure
(\eg auto-scaling, relocating workloads between sites, re-scheduling faulty
resources across sites).
% should be elaborated and/or refs should be given here

\paragraph{L3: Robustness \wrt split brains:}
In this level, we consider split brains which correspond to the situation
where the infrastructure is partitioned due to communication failures.
\Cref{fig:fogedge-archi} depicts such situation where \emph{Site 1} can be
isolated from the other sites. In such case, we distinguish two cases: (i) when
a partition is composed of an single site, like \emph{Site 1} in the figure,
all operations defined in L1 must be guaranteed regarding this site, supposing
it is reachable). For instance, a user in \emph{Site 1} must be
able to use \emph{Site 1}'s resources despite the split brain. Regarding
partitions containing several sites, L1 and L2 operations must be guaranteed
for any set of sites inside the partition.
% what about quotas? how to manage them in case of split-brain?
% suppose a user has a global quotas on several sites, it is impossible to
% determine its global consumption in case of split-brains?
Two sub-levels are proposed here: L3.1 considers the robustness of already
deployed resources (\eg a user should be able to access a deployed application
despite the split brain, if he can reach the related site), and is thus limited
to users, while the robustness of management services, treated in L3.2, is
required for both admins and users.
% tricky issue: management of split brain between collaborative services in
% different sites

\paragraph{L4: Multiple Cloud environments:}
Since edge infrastructures are dynamic infrastructures where sites can join and
leave, different versions of an IaaS manager can exist on different sites. One
requirement here is to consider L3 requirements between sites operated by
different manager versions (L4.1). Another requirement is to prevent vendor
lock-in between multiple generic IaaS manager technologies (\eg OpenStack,
CloudStack), and container orchestrators like Kubernetes (L4.2).
As a consequence, it is necessary to discover site's capabilities to determine
their compatibilities. For instance, it is not possible to migrate a VM from
\emph{Site 1} to \emph{Site 2} if the latter is managed by a container
orchestrator.

\paragraph{L5: Multiple operators:}
We now consider L4, plus the possibility that sites can be owned by different
operators. As depicted in \cref{tab:requirements}, no requirements is expected
by administrators since an operator would not share administrative rights to
their sites with other operators. However,
operators should be able to collaborate to offer their sites' resources to
users. Specific metrics should be collected at the scope of operators to
manage for instance billing between them.\\

%footer
Our classification of the requirements expected by both admins and users
highlights that the complexity to develop an edge infrastructure manager
significantly increases at each level. In fact, since L4 and L5 extends L3
respectively with multiple manager environments, and multiple operators, they
can be considered at the same level in our classification (and can be swapped
as a consequence).
Considering now that the challenges are already numerous with L1, L2 and L3, we
propose to drive the system design regarding these levels in the rest of the
paper (leaving L4 and L5 for future works).

