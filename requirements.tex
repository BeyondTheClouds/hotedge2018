
\section{Admin/DevOps' Requirements}
\label{sec:requirements}

% \begin{figure}[t]
%   \centering
%   \def\svgwidth{\columnwidth}
%   \input{figures/sites.pdf_tex}
%   \caption{Partial representation of the targeted edge infrastructure, composed
%     of multiple sites. Each site is composed of many servers (represented by
%     black bullets) and have a set of users (depicted by black squares). The red
%     dashed line depicts a split-brain situation that separates the
%     infrastructure into $2$ partitions, isolating \emph{Site 1} from \emph{Site
%     2} and \emph{3}.}
%   \label{fig:fogedge-archi}
% \end{figure}

\begin{table*}
    \centering
    \input{tab_req.tex}
    \vspace*{-.2cm}
    \caption{Classification of the requirements to administer and use
    \edgecomputing infrastructures in $5$ levels.}
  \label{tab:requirements}
      \vspace*{-.4cm}
\end{table*}

Herein we classify features administrators and DevOps expect
to find in the context of \edgecomputing infrastructures.
The classification is based on $5$ \emph{levels}, starting from the easiest
aspects, \ie interacting with a single site (considered in level 1, L1), to
more complex aspects like managing multiple sites (L2), up to taking into account that
sites can be owned by different operators (L5).
\Cref{tab:requirements} summarizes the classification we detail below.

As previously mentioned, a large part of these features are common to
the ones offered by current IaaS resource management systems. They are
implemented by various services, each of which is in charge of the
management of a particular aspect of the infrastructure
%.In this paper, we consider the Compute, Storage and
%Network managers as well as the monitoring and administrative
%tools
~\cite{moreno2012csp}.
%\ALm{Not sure whether we should introduce
%  service here. Maybe this is something we should only put at the end
%  of this section to make a transition with the other ones. The issue
%  is that we need it for the moment in L2.}

\vspace*{-.3cm}
\paragraph{L1. Operate/use any site}
%As depicted in the second row of \cref{tab:requirements}, 
This level
considers the actions both administrators and DevOps expect to perform on a
single, reachable site.
%
Most operations are elementary from the \edge viewpoint because they correspond
to the ones already provided by a VIM such as OpenStack.
In other words, each \edge site can be considered as an independent \cloud at
this level. The unmanned aspect only impacts this level by requiring to perform
all operations remotely if needed.
%security
Furthermore, the resource management system should provide means to
ensure the integrity of the hardware resources taking part to the \edge
infrastructure. Strategies such as enabling/disabling physical
interactions with the equipment should be considered.

% %
% Regarding administrators,  Administrators should be able to
% install and upgrade the aforementioned resource management
% services. After what, they can use those services to manage
% users, accesses, flavors (\ie available capacities of compute
% resources) and quotas.

% Regarding DevOps, they should be able to provision compute, network or
% storage resources like any traditional Cloud platform, supposing they
% are authorized to.

% In addition, admins and users share common expectations.
% % collect metrics
% First they want to monitor various metrics related to resources,
% users, and projects . This is used for instance for
% respectively managing quotas and listing existing resources.

\vspace*{-.3cm}
\paragraph{L2. Operate/use several sites}

% For instance, a user of \emph{Site 1}
In L2, L1 features are considered but over several sites. This
includes operations such as provisioning/managing multiple resources or
gathering information from various sites simultaneously.
%(interconnecting two VMs with a dedicated network).
Operations can be either intra-service (same service from different sites) or
inter-service (different services from different sites). Examples of 
such operations include configuring users'
access on a per-site basis; listing available VM images or pushing new
ones on multiple sites. From the
DevOps viewpoint, a user should be able to boot a VM on \emph{Site 1}
% (depicted on \cref{fig:fogedge-archi})%
using an image defined in \emph{Site 2}
(inter-service operation). Similarly to L1, users also expect metrics to be collected
from several sites the availability of collaboration mechanisms regarding the security (\eg
secret key sharing, network encryption).

Because collaboration between sites can be either explicit (\ie the
targeted sites are explicitly specified in the operation), or implicit
(\ie the resource management system is in charge of selecting
resources), we have defined two sub-levels: L2.1 and L2.2, as depicted in
\cref{tab:requirements}.
The implicit
manner suggests that policies (\eg performance objectives, energy
consumption) and constraints (\eg affinity rules, hardware requirements) are
provided by admins/DevOps so that the resource management system takes the
right decisions regarding the defined desiderata and the state of the
infrastructure (\eg auto-scaling, relocating workloads between sites,
re-scheduling faulty resources across sites).
% should be elaborated and/or refs should be given here

\paragraph{L3. Robustness \wrt network split-brains}
%Because of potential intermittent connections between edge sites,
L3 includes L2 operations but with the possibility to face situations
where the infrastructure is partitioned due to network disconnections.
%
\Cref{fig:fogedge-archi} depicts such a case where \emph{Site 1} is isolated
from the other sites. In this scenario, administrators/DevOps that can reach \emph{Site
1} (\ie located in the same geographical area) should be able to perform L1
operations on \emph{Site 1} despite the split-brain. Such a requirement
makes sense as L1 is limited to one site and does not impact other ones.
%
%Regarding the $2$\textsuperscript{nd} partition containing the other
For the remaining sites, L1
and L2 must be guaranteed.
% for any subset of sites inside the partition.

Since split-brains might impact differently already-provisioned resources and
management services, we refine L3 into two sub-features. L3.1 is
related to features that allow already-deployed applications to continue to
serve local requests without being impacted. For instance, an \emph{apache}
server or a storage backend should be able to satisfy requests coming from the
same geographical area, even if management services cannot be reached. L3.2
features are related to the provisioning of new resources and other management
operations as described in the previous paragraph.
%
Note that guaranteeing L2 features will not be always possible at the L3.2
level because information cannot be gathered in case of a disconnection. For
instance, guaranteeing quotas across the infrastructure might be a challenge %overall is impossible
without first relaxing the consistency requirement of the information. New approaches will have
to be proposed for such operations.

Finally, the possibly intermittent network connectivity between \edge resources
requires the ability for sites to join and leave the
infrastructure.

% what about quotas? how to manage them in case of split-brain?
% suppose a user has a global quotas on several sites, it is impossible to
% determine its global consumption in case of split-brains?

\vspace*{-.3cm}
\paragraph{L4. Multiple \cloud environments}
Delivering a resource management system at large scale in a unified manner %might be
%not conceivable from the 
poses a great challenge from the software viewpoint. Since different versions and types
of infrastructure managers might co-exist at the same time across the whole
infrastructure, L4 gathers the related requirements.
%
More precisely, L4.1 considers L3 features when different versions of the same software stack co-exist across the infrastructure.
%
L4.2 increases the complexity by considering  the collaboration of mutiple systems, including possibly different concepts (\eg
OpenStack for VMs and Kubernetes for Containers).
%
Such a requirement implies the ability to get sites' capabilities in order to
only allow meaningful collaborations.

\vspace*{-.3cm}
\paragraph{L5. Multiple operators}
L5 corresponds to the holy grail in terms of expected features. In addition to
L4, it includes the possibility to use sites owned by different operators. %As
%depicted in \cref{tab:requirements}, 
We do not specify any requirement for
administrators at this level as an operator is unlikely to let other operators administer
its own site. However, operators should be able to collaborate to offer their
sites' resources to any DevOps like it has been done for a while for cellular
networks. The requirements here are more related to the collection and sharing of
relevant metrics enabling each operator to perform charging/billing.

%footer
\vspace*{-.3cm}
\paragraph{Summary}
As previously mentioned, each level of our classification increases the
complexity in terms of design and development constraints. Note however that
since L4 and L5 both extend L3, they can be considered at the same level and
can be swapped as a consequence.

Although we tried to be exhaustive, this list of features could
probably be extended, \eg by considering different \edge
infrastructure scenarios (\eg including smaller and limited devices).
However, we believe it is already valuable as it delivers significant
insights on the design and implementation of an \edge resource management
system. In the next section, we study whether OpenStack can fulfill the L1, L2,
and L3 levels. The discussion of L4 and L5 is left as future work.

%Considering now that the challenges are already numerous with L1, L2 and L3, we
%propose to drive the system design regarding these levels in the rest of the
%paper (leaving L4 and L5 for future works).
