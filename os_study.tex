%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
\section{OpenStack at The Edge}
\label{sec:system_design_considerations}
\AL{We should add one sentence that justify why we have this section}
%
This section studies the use of OpenStack to control an Edge
infrastructure.  It evaluates the system in regards to the
requirements defined in the previous section, highlighting why changes
are mandatory in its codebase.

At coarse-grained, an OpenStack system consists of two kinds of nodes. On the one hand,
there are compute/storage/network nodes which deliver the XaaS
capabilities, such as hosting VMs (\ie data plane). On the other hand,
they are control nodes which execute the OpenStack services (\ie
control plane).
%
Administrator or a DevOps performs an action on OpenStack, the control
plane processes that action which ends on compute/storage/network
nodes.
%
Among the most important control plane services, one can cite
\verb|keystone|, \verb|nova| (VM lifecycle), \verb|glance| (VM
images), and \verb|neutron|, whose respectively are in charge of the
authentification, the VM life cycle, their images and the network
aspects.

Because OpenStack comes with several deployment possibilities and
because the edge sites we are considering in our study can host
control and compute capabilities, we discuss two scenarios: The first
one mimics the infrastructure of the Cloud Computing by deploying all
control services on one site of the infrastructure and uses resources
available on the other sites as compute nodes.  The second one
corresponds to a specific multi-region deployment, where one OpenStack
per Edge site is deployed.

\subsection{Centralized (Remote) Management}
\label{subsec:centralized_os}
In this first scenario, OpenStack operates an Edge infrastructure
like a traditional Cloud Computing one. The ``only'' difference is
related to the wide-area network links between the control services
and the compute nodes. The distinction between the different Edge
sites can be done by leveraging the concept of host aggregates
provided by OpenStack.
%
From the requirements' viewpoint, L1 and most L2 requirements can be
fulfilled in a straightforward way. Note however that because the
infrastructure can be spread over several network domains, advanced
network operations cannot be satisfied. In addition, the scalability
limitation of this deployment will prevent it to consider thousands of
compute nodes.
%
Requirements of L3 cannot be met. Most OpenStack services create and
manipulate logical objects that are persisted in shared databases.
While this enables service to easily collaborate, it imposes a
permanent connectivity between compute nodes, services and their DBs.
In other words, while this scenario provides a ``Single Pane of
Glass'' for administrator and DevOps, it has the drawback of being a
``Single Point of Failure'' preventing DevOps to use Edge resources in
case of network split brains.



\subsection{Multiple Regions}
In this second scenario, each Edge site corresponds to a \emph{region}
in the OpenStack terminology, which is a complete deployment of
OpenStack including all control services with a ``shared'' Keystone.
% (\ie the identify and service provider).
The main advantage of this
deployment is related to the independency of each site in case of
network disconnections. In other words, in case of a network split,
each site can satisfy the L1 features. The downside is related to the
fact that the current codebase does not provide any mechanism to allow
the collaboration between several regions and thus L2 requirements
cannot be met.


\subsection{Effective Collaboration is Needed}
Despite the fallibility of the network, and frequent isolation risks
of an Edge site from the rest of the Infrastructure, the Edge
infrastructure may be kept sustainable to meet L3 requirements. This
is achieved by supposing a collaboration a la \emph{peer-to-peer},
that is, an Edge site always serves local resources and collaborates
with other Edge sites if need be. To develop such a resource
management system, the developer has two fundamental design options:
\emph{top-down} or \emph{bottom-up}. Both designs impact how to handle
the collaboration needed by the system.

A top-down collaboration design implements the collaboration by
federating VIMs' API. It leverages on existing VIMs as they are made
available today without introducing modifications/extensions. Examples
of approaches following a \emph{top-down} design are:
ONAP~\cite{onap}, Kingbird~\cite{kingbird},
FogBow~\cite{brasileiro2016fogbow} and
p2p-OpenStack~\cite{ericsson-p2p}

A bottom-up collaboration design lays on making VIMs
mechanisms/services directly collaborative~\cite{7923796}. For example, having two
OpenStack Nova services able to cooperate and communicate directly
would be a realization of a bottom-up design. Such design implies
either the modification/extension of existing VIMs or the creation of
a completely new system.